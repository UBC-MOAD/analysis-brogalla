{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Monthly CESM ice flux files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import netCDF4 as nc\n",
    "import numpy as np\n",
    "import datetime\n",
    "from mpl_toolkits.basemap import Basemap, cm\n",
    "import cmocean\n",
    "import matplotlib\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "code_show=true; \n",
       "function code_toggle() {\n",
       " if (code_show){\n",
       " $('div.input').hide();\n",
       " } else {\n",
       " $('div.input').show();\n",
       " }\n",
       " code_show = !code_show\n",
       "} \n",
       "$( document ).ready(code_toggle);\n",
       "</script>\n",
       "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "\n",
    "HTML('''<script>\n",
    "code_show=true; \n",
    "function code_toggle() {\n",
    " if (code_show){\n",
    " $('div.input').hide();\n",
    " } else {\n",
    " $('div.input').show();\n",
    " }\n",
    " code_show = !code_show\n",
    "} \n",
    "$( document ).ready(code_toggle);\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" value=\"Click here to toggle on/off the raw code.\"></form>''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stuff that doesn't need to be loaded every time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask  = nc.Dataset('/ocean/brogalla/GEOTRACES/ariane_runs/ANHA12_Ariane_mesh.nc')\n",
    "tmask = np.array(mask.variables['tmask'])\n",
    "tmask = np.array(tmask[0,:,:,:])\n",
    "\n",
    "mesh  = nc.Dataset('/data/brogalla/old/meshmasks/ANHA12_mesh1.nc')\n",
    "mlons = np.array(mesh.variables['nav_lon'])\n",
    "mlats = np.array(mesh.variables['nav_lat'])\n",
    "mlons = np.array(mlons)\n",
    "mlats = np.array(mlats)\n",
    "\n",
    "cond = (tmask > 0.1) \n",
    "Z_masked = np.ma.masked_where(cond, tmask) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_file(filename, field1, field2, field3):\n",
    "    ncd = nc.Dataset(filename, 'w', zlib=True)\n",
    "#     nc_tools.init_dataset_attrs(\n",
    "#         ncd,\n",
    "#         title='dust input field',\n",
    "#         notebook_name='',\n",
    "#         nc_filepath='./dust_input.nc',\n",
    "#         comment='NCAR deposition field')\n",
    "\n",
    "    ncd.createDimension('x',len(mesh.dimensions['x']))\n",
    "    ncd.createDimension('y',len(mesh.dimensions['y']))\n",
    "    ncd.createDimension('time_counter',None)\n",
    "    \n",
    "    # variables\n",
    "    dust             = ncd.createVariable('dust', 'float64', ('y','x'))\n",
    "    dust.units       = 'kg/m2 s'\n",
    "    dust.long_name   = 'Dust deposition flux'  \n",
    "    dust.coordinates = 'nav_lon nav_lat'\n",
    "    dust[:]          = field1[:]\n",
    "    \n",
    "    bc_philic             = ncd.createVariable('bc_philic', 'float64', ('y','x'))\n",
    "    bc_philic.units       = 'kg/m2 s'\n",
    "    bc_philic.long_name   = 'Hydrophilic black carbon'  \n",
    "    bc_philic.coordinates = 'nav_lon nav_lat'\n",
    "    bc_philic[:]          = field2[:]\n",
    "    \n",
    "    bc_phobic             = ncd.createVariable('bc_phobic', 'float64', ('y','x'))\n",
    "    bc_phobic.units       = 'kg/m2 s'\n",
    "    bc_phobic.long_name   = 'Hydrophobic black carbon'  \n",
    "    bc_phobic.coordinates = 'nav_lon nav_lat'\n",
    "    bc_phobic[:]          = field3[:]\n",
    "    \n",
    "    print('saved ', filename)\n",
    "\n",
    "    ncd.close()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interp_np(nav_lon, nav_lat, var_in, lon_ANHA12, lat_ANHA12):\n",
    "    ''' Interpolate some field to ANHA12 grid.\n",
    "        The function is based on the bilinear interpolation in scipy, griddata \n",
    "        =======================================================================\n",
    "            nav_lon, nav_lat        : input field lon/lat\n",
    "            lon_ANHA12, lat_ANHA12  : ANHA12 defined lons/lats\n",
    "            var_in                  : 2-D model variable\n",
    "    '''\n",
    "    from scipy.interpolate import griddata\n",
    "    LatLonPair = (nav_lon, nav_lat)\n",
    "    var_out = griddata(LatLonPair, var_in, (lon_ANHA12, lat_ANHA12), method='linear')\n",
    "    # Take nearest neighbour interpolation to fill nans\n",
    "    var_fill = griddata(LatLonPair, var_in, (lon_ANHA12, lat_ANHA12), method='nearest')\n",
    "    \n",
    "    var_out[np.isnan(var_out)] = var_fill[np.isnan(var_out)]\n",
    "    return var_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = '/ocean/brogalla/GEOTRACES/data/NCAR/'\n",
    "faero_001_nh   = 'merged_faero_ocn001_nh.nc' #hydrophilic black carbon\n",
    "faero_002_nh   = 'merged_faero_ocn002_nh.nc' #hydrophobic black carbon\n",
    "faero_003_nh   = 'merged_faero_ocn003_nh.nc' #dust\n",
    "\n",
    "faero_001_n = nc.Dataset(folder+faero_001_nh)\n",
    "faero_002_n = nc.Dataset(folder+faero_002_nh)\n",
    "faero_003_n  = nc.Dataset(folder+faero_003_nh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocn001 = faero_001_n.variables['faero_ocn001']\n",
    "ocn002 = faero_002_n.variables['faero_ocn002']\n",
    "ocn003 = faero_003_n.variables['faero_ocn003']\n",
    "ocn001 = np.array(ocn001)\n",
    "ocn002 = np.array(ocn002)\n",
    "ocn003 = np.array(ocn003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond = (ocn001 >= 1e30) \n",
    "ocn001_masked = np.ma.masked_where(cond, ocn001) \n",
    "# np.count_nonzero(ocn001_masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond = (ocn002 >= 1e30) \n",
    "ocn002_masked = np.ma.masked_where(cond, ocn002) \n",
    "# np.count_nonzero(ocn002_masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond = (ocn003 >= 1e30) \n",
    "ocn003_masked = np.ma.masked_where(cond, ocn003) \n",
    "# np.count_nonzero(ocn003_masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lon  = faero_001_n.variables['TLON']\n",
    "lat  = faero_001_n.variables['TLAT']\n",
    "time = faero_001_n.variables['time']\n",
    "\n",
    "lon = np.array(lon)\n",
    "for i in range(0,104):\n",
    "    for j in range(0,320):\n",
    "        if lon[i,j] >= 180:\n",
    "            lon[i,j] = -360+lon[i,j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lons=np.array(lon)\n",
    "lats=np.array(lat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indicate year for which to create files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_year = 2002"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Timing structure:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time[0] = 192001, time[-1] = 208012"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "identify array indices corresponding to start and end of file_year:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_date_start = file_year*365\n",
    "file_date_end = (file_year+1)*365"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start index:  983\n",
      "end index:  995\n"
     ]
    }
   ],
   "source": [
    "start_index = []\n",
    "end_index = []\n",
    "\n",
    "for i in range(0,len(time)):\n",
    "    if time[i] == file_date_start:\n",
    "        start_index = i\n",
    "    elif time[i] == file_date_end:\n",
    "        end_index = i\n",
    "        \n",
    "print('start index: ', start_index)\n",
    "print('end index: ', end_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpolate to ANHA12 grid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interp_dst = np.empty((12, 2400, 1632))\n",
    "interp_bc1  = np.empty((12, 2400, 1632))\n",
    "interp_bc2  = np.empty((12, 2400, 1632))\n",
    "\n",
    "# loop over the months:\n",
    "for i in range(0,12):\n",
    "    filt_ocn001 = ocn001_masked[start_index+i,:,:][~ocn001_masked[start_index+i,:,:].mask].data\n",
    "    filt_ocn002 = ocn002_masked[start_index+i,:,:][~ocn002_masked[start_index+i,:,:].mask].data\n",
    "    filt_ocn003 = ocn003_masked[start_index+i,:,:][~ocn003_masked[start_index+i,:,:].mask].data\n",
    "    filt_lons1 = lons[~ocn001_masked[start_index+i,:,:].mask].data\n",
    "    filt_lons2 = lons[~ocn002_masked[start_index+i,:,:].mask].data\n",
    "    filt_lons3 = lons[~ocn003_masked[start_index+i,:,:].mask].data\n",
    "    filt_lats1 = lats[~ocn001_masked[start_index+i,:,:].mask].data\n",
    "    filt_lats2 = lats[~ocn002_masked[start_index+i,:,:].mask].data\n",
    "    filt_lats3 = lats[~ocn003_masked[start_index+i,:,:].mask].data\n",
    "    \n",
    "    interp_dst[i,:,:] = interp_np(filt_lons3, filt_lats3, filt_ocn003, mlons, mlats)\n",
    "    interp_bc1[i,:,:]  = interp_np(filt_lons1, filt_lats1, filt_ocn001, mlons, mlats)\n",
    "    interp_bc2[i,:,:]  = interp_np(filt_lons2, filt_lats2, filt_ocn002, mlons, mlats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.amax(interp_dst), np.amin(interp_dst))\n",
    "print(np.amax(interp_bc1), np.amin(interp_bc1))\n",
    "print(np.amax(interp_bc2), np.amin(interp_bc2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write to NetCDF files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "location='/data/brogalla/atmospheric_forcing/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved  /data/brogalla/atmospheric_forcing/ice_flux_y2020m01.nc\n",
      "saved  /data/brogalla/atmospheric_forcing/ice_flux_y2020m02.nc\n",
      "saved  /data/brogalla/atmospheric_forcing/ice_flux_y2020m03.nc\n",
      "saved  /data/brogalla/atmospheric_forcing/ice_flux_y2020m04.nc\n",
      "saved  /data/brogalla/atmospheric_forcing/ice_flux_y2020m05.nc\n",
      "saved  /data/brogalla/atmospheric_forcing/ice_flux_y2020m06.nc\n",
      "saved  /data/brogalla/atmospheric_forcing/ice_flux_y2020m07.nc\n",
      "saved  /data/brogalla/atmospheric_forcing/ice_flux_y2020m08.nc\n",
      "saved  /data/brogalla/atmospheric_forcing/ice_flux_y2020m09.nc\n",
      "saved  /data/brogalla/atmospheric_forcing/ice_flux_y2020m10.nc\n",
      "saved  /data/brogalla/atmospheric_forcing/ice_flux_y2020m11.nc\n",
      "saved  /data/brogalla/atmospheric_forcing/ice_flux_y2020m12.nc\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,13):\n",
    "    if i < 10:\n",
    "        save_file(location+'ice_flux_y'+str(file_year)+'m0'+str(i)+'.nc',interp_dst[i-1,:,:], \\\n",
    "                 interp_bc1[i-1,:,:], interp_bc2[i-1,:,:])\n",
    "    else:\n",
    "        save_file(location+'ice_flux_y'+str(file_year)+'m'+str(i)+'.nc',interp_dst[i-1,:,:], \\\n",
    "                 interp_bc1[i-1,:,:], interp_bc2[i-1,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
