{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CAA freshwater content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import netCDF4 as nc\n",
    "import os\n",
    "from itertools import compress\n",
    "import datetime as dt\n",
    "import glob\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Domain dimensions:\n",
    "imin, imax = 1480, 2180\n",
    "jmin, jmax = 160, 800\n",
    "isize = imax - imin\n",
    "jsize = jmax - jmin\n",
    "\n",
    "# Results folders:\n",
    "folder_ref = '/data/brogalla/run_storage/Mn-set4-202004/'\n",
    "folder_sed = '/data/brogalla/run_storage/Mn-nosed-202005/'\n",
    "folder_riv = '/data/brogalla/run_storage/riv-2a-202005/'\n",
    "folder_con = '/data/brogalla/run_storage/riv-2b-202005/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Load files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mesh  = nc.Dataset('/data/brogalla/old/meshmasks/ANHA12_mesh1.nc')\n",
    "lon   = np.array(mesh.variables['nav_lon'])\n",
    "lat   = np.array(mesh.variables['nav_lat'])\n",
    "mesh_bathy = np.array(mesh.variables['hdept'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref   = nc.Dataset('/data/brogalla/run_storage/Mn-set4-202004/ref-2002/ANHA12_EXH006_2002_monthly.nc',  'r')\n",
    "lons  = np.array(ref.variables['nav_lon'])\n",
    "lats  = np.array(ref.variables['nav_lat'])\n",
    "depth = np.array(ref.variables['deptht'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_diff(year):\n",
    "    \n",
    "    files_base  = np.sort(glob.glob(folder_ref+'ref-'   +str(year)+'/ANHA12_EXH006_5d*'))\n",
    "    files_glac  = np.sort(glob.glob(folder_riv+'riv-2a-'+str(year)+'/ANHA12_EXH006_5d*'))\n",
    "    files_cont  = np.sort(glob.glob(folder_con+'riv-2b-'+str(year)+'/ANHA12_EXH006_5d*'))\n",
    "    files_nosed = np.sort(glob.glob(folder_sed+'nosed-' +str(year)+'/ANHA12_EXH006_5d*'))\n",
    "\n",
    "    glacier_contribution   = np.empty((len(files_base),50,isize,jsize))\n",
    "    continent_contribution = np.empty((len(files_base),50,isize,jsize))\n",
    "    sediment_contribution  = np.empty((len(files_base),50,isize,jsize))\n",
    "    \n",
    "    for file_ind in range(0,len(files_base)):\n",
    "        base_fday  = nc.Dataset(files_base[file_ind]);\n",
    "        glac_fday  = nc.Dataset(files_glac[file_ind]);\n",
    "        cont_fday  = nc.Dataset(files_cont[file_ind]);\n",
    "        nosed_fday = nc.Dataset(files_nosed[file_ind]);\n",
    "\n",
    "        dmn_base  = np.array(base_fday.variables['dissolmn'])[0,:,:,:]\n",
    "        dmn_glac  = np.array(glac_fday.variables['dissolmn'])[0,:,:,:]\n",
    "        dmn_cont  = np.array(cont_fday.variables['dissolmn'])[0,:,:,:]\n",
    "        dmn_nosed = np.array(nosed_fday.variables['dissolmn'])[0,:,:,:]\n",
    "\n",
    "        glacier_contribution[file_ind,:,:,:]   = dmn_glac - dmn_base\n",
    "        continent_contribution[file_ind,:,:,:] = dmn_cont - dmn_base\n",
    "        sediment_contribution[file_ind,:,:,:]  = dmn_base - dmn_nosed\n",
    "    \n",
    "    return glacier_contribution, continent_contribution, sediment_contribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_dates(year):\n",
    "    #start_date and end_date are datetime objects\n",
    "    start_date = dt.datetime(year,1,1)\n",
    "    end_date   = dt.datetime(year,12,31,12)\n",
    "    \n",
    "    file_list1E = np.sort(os.listdir('/data/brogalla/run_storage/Mn-set4-202004/ref-'+str(year)+'/'))\n",
    "    file_list2 = np.sort(os.listdir('/data/brogalla/ANHA12/'))\n",
    "    \n",
    "    Vlist = [i[26:31]=='gridV' for i in file_list2]\n",
    "    gridV_list = list(compress(file_list2, Vlist))\n",
    "    dateV_list = [dt.datetime.strptime(i[14:25], \"y%Ym%md%d\") for i in gridV_list]\n",
    "    gridV_file_list = list(compress(gridV_list, [V > start_date and V < end_date for V in dateV_list]))\n",
    "    \n",
    "    dates = [dt.datetime.strptime(i[14:25], \"y%Ym%md%d\") for i in gridV_file_list]\n",
    "    \n",
    "    return dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Calculations:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create mask for CAA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_ini_CAA  = np.ones(lon.shape) # full domain size\n",
    "mask_ini_CAA[0:imin+10, :] = 0 # remove the boundaries\n",
    "mask_ini_CAA[imax-10:, :]  = 0\n",
    "mask_ini_CAA[:, 0:jmin]    = 0\n",
    "mask_ini_CAA[:, jmax-20:]  = 0\n",
    "\n",
    "# Define CAA using the longitudes\n",
    "mask_CAA = np.ma.masked_where((mesh_bathy > 800), mask_ini_CAA)\n",
    "mask_CAA = np.ma.masked_where(lon < -130, mask_CAA)\n",
    "\n",
    "mask_CAA_lons = np.ma.masked_where(mask_CAA==0, lon)\n",
    "mask_CAA_lats = np.ma.masked_where(mask_CAA==0, lat)\n",
    "\n",
    "mask_CAA_yr   = np.tile(mask_CAA[imin:imax,jmin:jmax], (73,50,1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And mask for Canada Basin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_ini_CB  = np.ones(lon.shape) # full domain size\n",
    "mask_ini_CB[0:imin+10, :] = 0 # remove the boundaries\n",
    "mask_ini_CB[imax-10:, :]  = 0\n",
    "mask_ini_CB[:, 0:jmin]    = 0\n",
    "mask_ini_CB[:, jmax-20:]  = 0\n",
    "\n",
    "# Define Canada Basin using the 800 m contour and longitudes\n",
    "# mask_CB = np.ma.masked_where((mesh_bathy < 800) & (lon > -150), mask_ini_CB)\n",
    "mask_CB = np.ma.masked_where((mesh_bathy < 3200), mask_ini_CB)\n",
    "mask_CB = np.ma.masked_where((lon > -80), mask_CB)\n",
    "\n",
    "mask_CB_lons = np.ma.masked_where(mask_CB==0, lon)\n",
    "mask_CB_lats = np.ma.masked_where(mask_CB==0, lat)\n",
    "\n",
    "mask_CB_yr   = np.tile(mask_CB[imin:imax,jmin:jmax], (73,50,1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_ini_fullCB  = np.ones(lon.shape) # full domain size\n",
    "mask_ini_fullCB[0:imin+10, :] = 0 # remove the boundaries\n",
    "mask_ini_fullCB[imax-10:, :]  = 0\n",
    "mask_ini_fullCB[:, 0+10:jmin] = 0\n",
    "mask_ini_fullCB[:, jmax-20:]  = 0\n",
    "\n",
    "# Define fullCB using the longitudes\n",
    "mask_fullCB = np.ma.masked_where((mesh_bathy < 800), mask_ini_fullCB)\n",
    "mask_fullCB = np.ma.masked_where((lon > -60), mask_fullCB)\n",
    "mask_fullCB = np.ma.masked_where((lon > -100) & (lat < 78), mask_fullCB)\n",
    "\n",
    "mask_fullCB_lons = np.ma.masked_where(mask_fullCB==0, lon)\n",
    "mask_fullCB_lats = np.ma.masked_where(mask_fullCB==0, lat)\n",
    "\n",
    "mask_fullCB_yr   = np.tile(mask_fullCB[imin:imax,jmin:jmax], (73,50,1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the continental Mn contribution to the CAA over time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2002\n",
      "2003\n",
      "2004\n",
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n",
      "2019\n"
     ]
    }
   ],
   "source": [
    "timeseries_glac = []\n",
    "timeseries_cont = []\n",
    "timeseries_ice  = []\n",
    "\n",
    "for year in range(2002, 2020):\n",
    "    print(year)\n",
    "    glacier, cont, sed = calculate_diff(year)\n",
    "    glacier_CAA    = np.ma.masked_where(mask_CAA_yr==0, glacier)\n",
    "    cont_CAA       = np.ma.masked_where(mask_CAA_yr==0, cont)\n",
    "    sedice_CAA     = np.ma.masked_where(mask_CAA_yr==0, sed)\n",
    "    \n",
    "    for fday in range(0,73):\n",
    "        glac_sum = np.ma.sum(glacier_CAA[fday,:,:,:])\n",
    "        cont_sum = np.ma.sum(cont_CAA[fday,:,:,:])\n",
    "        sed_sum  = np.ma.sum(sedice_CAA[fday,:,:,:])\n",
    "\n",
    "        timeseries_glac.append(glac_sum)\n",
    "        timeseries_cont.append(cont_sum)\n",
    "        timeseries_ice.append(sed_sum)\n",
    "        \n",
    "pickle.dump((timeseries_glac, timeseries_cont, timeseries_ice), \\\n",
    "            open('/ocean/brogalla/GEOTRACES/pickles/CAA_timeseries.pickle','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the continental Mn contribution to Canada Basin over time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2002\n",
      "2003\n",
      "2004\n",
      "2005\n",
      "2006\n",
      "2007\n",
      "2008\n",
      "2009\n",
      "2010\n",
      "2011\n",
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n",
      "2019\n"
     ]
    }
   ],
   "source": [
    "timeseries_glac_full = []\n",
    "timeseries_cont_full = []\n",
    "timeseries_ice_full  = []\n",
    "\n",
    "for year in range(2002, 2020):\n",
    "    print(year)\n",
    "    glacier, cont, sed = calculate_diff(year)\n",
    "    glacier_CB_full = np.ma.masked_where(mask_fullCB_yr==0, glacier)\n",
    "    cont_CB_full    = np.ma.masked_where(mask_fullCB_yr==0, cont)\n",
    "    sedice_CB_full  = np.ma.masked_where(mask_fullCB_yr==0, sed)\n",
    "    \n",
    "    for fday in range(0,73):\n",
    "        glac_sum_full = np.ma.sum(glacier_CB_full[fday,:,:,:])\n",
    "        cont_sum_full = np.ma.sum(cont_CB_full[fday,:,:,:])\n",
    "        sed_sum_full  = np.ma.sum(sedice_CB_full[fday,:,:,:])\n",
    "\n",
    "        timeseries_glac_full.append(glac_sum_full)\n",
    "        timeseries_cont_full.append(cont_sum_full)\n",
    "        timeseries_ice_full.append(sed_sum_full)\n",
    "        \n",
    "pickle.dump((timeseries_glac_full, timeseries_cont_full, timeseries_ice_full), \\\n",
    "            open('/ocean/brogalla/GEOTRACES/pickles/full_CB_timeseries.pickle','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2002\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'glacier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-ef89ce722343>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mglacier_central\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcont_central\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msed_central\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_diff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mglacier_CB_central\u001b[0m    \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasked_where\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_CB_yr\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglacier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mcont_CB_central\u001b[0m       \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasked_where\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_CB_yr\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcont\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0msedice_CB_central\u001b[0m     \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasked_where\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_CB_yr\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'glacier' is not defined"
     ]
    }
   ],
   "source": [
    "timeseries_glac_central = []\n",
    "timeseries_cont_central = []\n",
    "timeseries_ice_central  = []\n",
    "\n",
    "for year in range(2002, 2020):\n",
    "    print(year)\n",
    "    glacier_central, cont_central, sed_central = calculate_diff(year)\n",
    "    glacier_CB_central    = np.ma.masked_where(mask_CB_yr==0, glacier_central)\n",
    "    cont_CB_central       = np.ma.masked_where(mask_CB_yr==0, cont_central)\n",
    "    sedice_CB_central     = np.ma.masked_where(mask_CB_yr==0, sed_central)\n",
    "    \n",
    "    for fday in range(0,73):\n",
    "        glac_sum_central = np.ma.sum(glacier_CB_central[fday,:,:,:])\n",
    "        cont_sum_central = np.ma.sum(cont_CB_central[fday,:,:,:])\n",
    "        sed_sum_central  = np.ma.sum(sedice_CB_central[fday,:,:,:])\n",
    "\n",
    "        timeseries_glac_central.append(glac_sum_central)\n",
    "        timeseries_cont_central.append(cont_sum_central)\n",
    "        timeseries_ice_central.append(sed_sum_central)\n",
    "        \n",
    "pickle.dump((timeseries_glac_central, timeseries_cont_central, timeseries_ice_central), \\\n",
    "            open('/ocean/brogalla/GEOTRACES/pickles/central_CB_timeseries.pickle','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
